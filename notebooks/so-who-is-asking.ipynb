{"nbformat_minor": 0, "cells": [{"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "# Analyzing Stack Overflow Activity\n\nIn our developer advocacy team we keep an eye out on what is happening on Stack Overflow (SO). It is good to know what people are struggling with, and we try to help out by answering questions or writing blog posts and talks about the most common issues. \n\nOur team advocates for a range of products for IBM. In this analysis I focused on `cloudant`, `couchdb`, `dashdb` and `pouchdb`, which are four different databases closely linked. **Linked how?** These questions are stored in a [Cloudant] database. **Patrick: how?**\n\nFor the analysis of the data from these 2060 questions I used a Jupyter Python notebook on the [IBM Data Science Experience]() that you can find on [github](). In this notebook the SO data is analysed to try to find out what more about the users by answering the following questions:\n\n1. How many unique users are there and what questions do they ask? \n1. Are users asking questions with different tags, or only about one product? \n1. Are users (owners) beginners or more experienced?\n1. Does the number of users change over time?\n\nAnd some other possible questions:\n\n* How long are the questions active for?\n* What is the rating of the questions grouped by tag?\n* Can we find users on twitter and see what they say there?\n* What is the sentiment in the questions and answers?\n* Is there a relationship between ranking of the question and the lenght?\n* What are the best questions to ask or answer to increase your reputation?\n\n\n## Load and clean the data\n\nAs the data is stored in Cloudant, the first step is to load the data into the notebook, clean up the data and covert it into a pandas DataFrame. "}, {"cell_type": "markdown", "metadata": {}, "source": "### Prerequisites"}, {"cell_type": "markdown", "metadata": {}, "source": "Import PixieDust, enable the Apache Spark Job monitor and load some more packages.\n\nInstall or update missing packages with `!pip install --user <package>`."}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "import pixiedust\npixiedust.enableJobMonitor()", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "from pyspark.sql.functions import explode\nfrom pyspark.sql import functions as F\n\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\nfrom io import BytesIO, StringIO  \nimport requests  \nimport json  \n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Configure database connectivity\n\nCustomize this cell with your Cloudant/CouchDB connection information"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# @hidden_cell\n# Enter your Cloudant host name\nhost = '--myhostname--'\n# Enter your Cloudant user name\nusername = '--myusername--'\n# Enter your Cloudant password\npassword = '--mysecretpassword--'\n# Enter your source database name\ndatabase = '--mydatabasename--'", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Load documents from the database\n\nLoad the documents into an Apache Spark DataFrame and describe the data structure."}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# no changes are required to this cell\n# obtain Spark SQL Context\nsqlContext = SQLContext(sc)\n# load data\nso_data = sqlContext.read.format(\"com.cloudant.spark\").\\\n                                 option(\"cloudant.host\", host).\\\n                                 option(\"cloudant.username\", username).\\\n                                 option(\"cloudant.password\", password).\\\n                                 load(database)              \nso_data.cache()                ", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "so_data.printSchema()\nso_data.count()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Clean up data and convert to a pandas DataFrame\n\nSelect only the relevant data and convert it to a table. As the tags column consists of a string, also add columns for each tag in the string by using a `lambda` function. For the further analysis it is also handy to have boolean data about the occurence of the 4 tags of interest. These can also be added with a `lambda` function."}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# all users\nsodf = so_data.select(so_data.question.question_id.alias(\"id\"),\n                       so_data.question.owner.accept_rate.alias(\"accept_rate\"),\n                       so_data.question.owner.reputation.alias(\"reputation\"),\n                       so_data.question.owner.user_id.alias(\"user_id\"),\n                       so_data.question.answer_count.alias(\"answer_count\"), \n                       so_data.question.creation_date.alias(\"creation\"), \n                       so_data.question.closed_date.alias(\"closed\"),\n                       so_data.question.is_answered.alias(\"answered\"),\n                       so_data.question.score.alias(\"score\"),\n                       so_data.question.view_count.alias(\"views\"),\n                       so_data.question.title.alias(\"title\"),\n                       so_data.question.tags.alias(\"tags\")).toPandas()", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "tags = sodf['tags'].apply(pd.Series)\ntags = tags.rename(columns = lambda x: 'tags_' + str(x))\n\nsodf = pd.concat([sodf[:], tags[:]], axis=1)\n\nsodf['cloudant']=sodf['tags'].apply(lambda x: 'cloudant' in x)\nsodf['dashdb']=sodf['tags'].apply(lambda x: 'dashdb' in x)\nsodf['couchdb']=sodf['tags'].apply(lambda x: 'couchdb' in x)\nsodf['pouchdb']=sodf['tags'].apply(lambda x: 'pouchdb' in x)\n\nsodf.head()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Save the DataFrame in object-store\n\nTo save some time and reduce the number of times loading the data from Cloudant save `sodf` to a csv file in object-store. This will speed up the analysis when coming back to the notebook, you can just start by loading the data. "}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# @hidden_cell\ncredentials_1 = {\n  'auth_url':'https://identity.open.softlayer.com',\n  'project':'object_storage_de9e50d4_b6ba_4f25_926a_75c568e896a0',\n  'project_id':'f564592bf4d24d41b89ea8229243fa05',\n  'region':'dallas',\n  'user_id':'5c8116961cf345dfb9d75c5cb24a2e47',\n  'domain_id':'299db6126ac14081bf872905c18ba585',\n  'domain_name':'790621',\n  'username':'member_fbf96b4f9f669a48110776d13d879b48d00c7a25',\n  'password':\"\"\"D]2x4Ms&FMywU_Ez\"\"\",\n  'container':'SOanalysis',\n  'tenantId':'undefined',\n  'filename':'wordcloud.txt'\n}    ", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "sodf.to_csv('SOdata.csv', index=False, encoding='utf-8')\n\ndef put_file(credentials, local_file_name):  \n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage V3.\"\"\"\n    f = open(local_file_name,'r')\n    my_data = f.read()\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n            'password': credentials['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', credentials['container'], '/', local_file_name])\n    s_subject_token = resp1.headers['x-subject-token']\n    #headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json', 'Content-type':'application/json; charset=utf-8'}\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2, data = my_data )\n    print resp2\n    \nput_file(credentials_1, 'SOdata.csv')", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Read the DataFrame from the saved csv file in object store"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# @hidden_cell\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef get_object_storage_file_with_credentials_de9e50d4b6ba4f25926a75c568e896a0(container, filename):\n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage.\"\"\"\n\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_fbf96b4f9f669a48110776d13d879b48d00c7a25','domain': {'id': '299db6126ac14081bf872905c18ba585'},\n            'password': 'D]2x4Ms&FMywU_Ez'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO(resp2.text)\n\nsodf2 = pd.read_csv(get_object_storage_file_with_credentials_de9e50d4b6ba4f25926a75c568e896a0('SOanalysis', 'SOdata.csv'))\nsodf2.head()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "## What can we learn from the data?\n\nLets start with some basic numbers."}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "print len(np.unique(sodf2['user_id'])), 'users asked', len(sodf2), 'questions between',datetime.fromtimestamp(sodf2['creation'].min()).strftime('%Y-%m-%d'), 'and', datetime.fromtimestamp(sodf2['creation'].max()).strftime('%Y-%m-%d')\n\nprint sodf2['answer_count'].where(sodf2['cloudant']).count(),  'questions were about Cloudant.'  \nprint sodf2['answer_count'].where(sodf2['dashdb']).count(),  'questions were about dashDB.'  \nprint sodf2['answer_count'].where(sodf2['couchdb']).count(),  'questions were about couchDB.'  \nprint sodf2['answer_count'].where(sodf2['pouchdb']).count(),  'questions were about pouchDB.'  ", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "These numbers look good in a bar chart as well. Average values and ranges of number of views, accept rate and reputation are easy to compare with boxplots. "}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "reputation = [sodf2['reputation'].where(sodf2['cloudant']).dropna(), sodf2['reputation'].where(sodf2['dashdb']).dropna(),\n             sodf2['reputation'].where(sodf2['couchdb']).dropna(), sodf2['reputation'].where(sodf2['pouchdb']).dropna()]\n\nviews = [sodf2['views'].where(sodf2['cloudant']).dropna(), sodf2['views'].where(sodf2['dashdb']).dropna(),\n             sodf2['views'].where(sodf2['couchdb']).dropna(), sodf2['views'].where(sodf2['pouchdb']).dropna()]\n\naccept = [sodf2['accept_rate'].where(sodf2['cloudant']).dropna(), sodf2['accept_rate'].where(sodf2['dashdb']).dropna(),\n             sodf2['accept_rate'].where(sodf2['couchdb']).dropna(), sodf2['accept_rate'].where(sodf2['pouchdb']).dropna()]\n\nquestions = [sodf2['answer_count'].where(sodf2['cloudant']).count(),sodf2['answer_count'].where(sodf2['dashdb']).count(),\n            sodf2['answer_count'].where(sodf2['couchdb']).count(),sodf2['answer_count'].where(sodf2['pouchdb']).count()]\n\nanswers = [sodf2['answer_count'].where(sodf2['cloudant']).sum(), sodf2['answer_count'].where(sodf2['dashdb']).sum(),\n          sodf2['answer_count'].where(sodf2['couchdb']).sum(), sodf2['answer_count'].where(sodf2['pouchdb']).sum()]\n\nscore = [sodf2['score'].where(sodf2['cloudant']).dropna(), sodf2['score'].where(sodf2['dashdb']).dropna(),\n          sodf2['score'].where(sodf2['couchdb']).dropna(), sodf2['score'].where(sodf2['pouchdb']).dropna()]\n\nticks = ['cloudant','dashdb','couchdb','pouchdb']\n\nfig = plt.subplots(nrows=3, ncols=2, figsize=(16, 10))\n\nax0 = plt.subplot(321)\nind = np.arange(4)\nwidth = 0.35       \nax0.bar(ind, questions, width, color='r')\nax0.bar(ind+0.35, answers, width, color='b')\nax0.set_xticks(0.2 + (ind + width / 2))\nax0.set_xticklabels(ticks)\nax0.legend(('Questions', 'Answers'))\n\nax1 = plt.subplot(322)\nax1.boxplot(reputation)\nax1.set_ylim([0,1000])\nax1.set_ylabel('Reputation')\nax1.set_xticklabels(ticks)\n\nax2 = plt.subplot(323)\nax2.boxplot(views)\nax2.set_ylim([0,600])\nax2.set_ylabel('Views')\nax2.set_xticklabels(ticks)\\\n\nax3 = plt.subplot(324)\nax3.boxplot(accept)\n#ax3.set_ylim([0,600])\nax3.set_ylabel('Accept rate')\nax3.set_xticklabels(ticks)\n\nax3 = plt.subplot(325)\nax3.boxplot(score)\nax3.set_ylim([-2,3])\nax3.set_ylabel('Score')\nax3.set_xticklabels(ticks)\nplt.tight_layout()\n", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "## Most popular questions\n\npopularity = f(views,score,tags)\n\nviews = f(question age)\n\nMight need to explode the data, duplicating questions when multiple tags\n\nClassify or group questions?"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "", "metadata": {"collapsed": true}}, {"cell_type": "markdown", "metadata": {}, "source": "Maybe there are some correlations between variables. Let's try with some quick scatter plots. Note that the axes are cut off, because the outliers made it hard to see anything. Anyways, no correlations there on first sight. Not entirely sure what I am trying to find here actually.  "}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "list(sodf2)\n\nfig = plt.subplots(nrows=2, ncols=2, figsize=(13, 8))\n\nax0 = plt.subplot(221)\nax0.scatter(sodf2.reputation.where(sodf2['couchdb']), sodf2.views.where(sodf2['couchdb']),color='g')\nax0.scatter(sodf2.reputation.where(sodf2['pouchdb']), sodf2.views.where(sodf2['pouchdb']),color='orange')\nax0.scatter(sodf2.reputation.where(sodf2['cloudant']), sodf2.views.where(sodf2['cloudant']),color='r')\nax0.scatter(sodf2.reputation.where(sodf2['dashdb']), sodf2.views.where(sodf2['dashdb']),color='b')\nax0.set_ylim([0,2500])\nax0.set_xlim([0,2000])\nax0.set_ylabel('Views')\nax0.set_xlabel('Reputation')\nax0.legend(('couchdb','pouchdb','cloudant','dashdb'))\n\nax1 = plt.subplot(222)\nax1.scatter(sodf2.reputation.where(sodf2['couchdb']), sodf2.accept_rate.where(sodf2['couchdb']),color='g')\nax1.scatter(sodf2.reputation.where(sodf2['pouchdb']), sodf2.accept_rate.where(sodf2['pouchdb']),color='orange')\nax1.scatter(sodf2.reputation.where(sodf2['cloudant']), sodf2.accept_rate.where(sodf2['cloudant']),color='r')\nax1.scatter(sodf2.reputation.where(sodf2['dashdb']), sodf2.accept_rate.where(sodf2['dashdb']),color='b')\nax1.set_ylim([-2,102])\nax1.set_xlim([0,2000])\nax1.set_ylabel('Accept rate')\nax1.set_xlabel('Reputation')\n\nax2 = plt.subplot(223)\nax2.scatter(sodf2.score.where(sodf2['couchdb']), sodf2.views.where(sodf2['couchdb']),color='g')\nax2.scatter(sodf2.score.where(sodf2['pouchdb']), sodf2.views.where(sodf2['pouchdb']),color='orange')\nax2.scatter(sodf2.score.where(sodf2['cloudant']), sodf2.views.where(sodf2['cloudant']),color='r')\nax2.scatter(sodf2.score.where(sodf2['dashdb']), sodf2.views.where(sodf2['dashdb']),color='b')\n#ax2.set_ylim([-2,102])\nax2.set_ylim([0,2500])\nax2.set_xlabel('Score')\nax2.set_ylabel('Views')\n\nax3 = plt.subplot(224)\nax3.scatter(sodf2.score.where(sodf2['couchdb']), sodf2.accept_rate.where(sodf2['couchdb']),color='g')\nax3.scatter(sodf2.score.where(sodf2['pouchdb']), sodf2.accept_rate.where(sodf2['pouchdb']),color='orange')\nax3.scatter(sodf2.score.where(sodf2['cloudant']), sodf2.accept_rate.where(sodf2['cloudant']),color='r')\nax3.scatter(sodf2.score.where(sodf2['dashdb']), sodf2.accept_rate.where(sodf2['dashdb']),color='b')\nax3.set_ylim([-2,102])\n#ax3.set_ylim([0,2500])\nax3.set_xlabel('Score')\nax3.set_ylabel('Accept rate')\n\nplt.tight_layout()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "As there is data for two years, there might be trends over time!\n\n**TODO: summarize number of questions per month etc.**"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "sodf2['date']=sodf2['creation'].apply(lambda x: datetime.fromtimestamp(x))\n\nper1 = sodf2.date.dt.to_period(\"M\")\ng1 = sodf2.groupby(per1)\ng2 = g1.sum()\n\n#g2.head()\n\ng2.\nlist(g2)\n\n", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "\n\n\nfig = plt.subplots(nrows=2, ncols=1, figsize=(20, 8))\n\nax0 = plt.subplot(211)\nax0.plot(g2.index,g2.pouchdb,color='g')\n#ax0.plot(sodf2.date.where(sodf2['pouchdb']), sodf2.views.where(sodf2['pouchdb']),color='orange')\n#ax0.plot(sodf2.date.where(sodf2['cloudant']), sodf2.views.where(sodf2['cloudant']),color='r')\n#ax0.plot(sodf2.date.where(sodf2['dashdb']), sodf2.views.where(sodf2['dashdb']),color='b')\nax0.set_ylim([0,500])\n#ax0.set_xlim([0,2000])\n#ax0.set_ylabel('Views')\n#ax0.set_xlabel('Reputation')\nax0.legend(('couchdb','pouchdb','cloudant','dashdb'))\n\n#ax0.plot(sodf2.date.where(sodf2['couchdb']), sodf2.score.where(sodf2['couchdb']),color='g')\n#ax0.plot(sodf2.date.where(sodf2['pouchdb']), sodf2.views.where(sodf2['pouchdb']),color='orange')\n#ax0.plot(sodf2.date.where(sodf2['cloudant']), sodf2.views.where(sodf2['cloudant']),color='r')\n#ax0.plot(sodf2.date.where(sodf2['dashdb']), sodf2.views.where(sodf2['dashdb']),color='b')\n\n\n#sodf2.head()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### 1 . Word cloud of all tags\n\nA quick [word cloud](https://github.com/amueller/word_cloud) to see which tags are used most. "}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# change the numbers [h,s,l = hue, saturation, ...] for different colors\ndef random_color_func(word=None, font_size=None, position=None,  orientation=None, font_path=None, random_state=None):\n    h = int(360.0 * 140.0 / 255.0)\n    s = int(150.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(50, 150)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\ntagtext = sodf2['tags'].to_string()\n#tagtext2 = tagtext.split()\n#tagtext2\n\nstopwords = set(STOPWORDS)\nstopwords.add(\"bluemix\")\nstopwords.add(\"ibm\")\nstopwords.add(\"NaN\")\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(16, 24))\n\nwordcloud = WordCloud(background_color=\"white\", margin=10, random_state=1, \n                      color_func=random_color_func, stopwords=stopwords, \n                     max_font_size=40, min_font_size=9).generate(tagtext)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Comparison of word clouds for cloudant, couchdb, dashdb and pouchdb."}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "tagtext1 = sodf2['tags'].where(sodf2['cloudant']).to_string()\ntagtext2 = sodf2['tags'].where(sodf2['dashdb']).to_string()\ntagtext3 = sodf2['tags'].where(sodf2['couchdb']).to_string()\ntagtext4 = sodf2['tags'].where(sodf2['pouchdb']).to_string()\n\nstopwords = set(STOPWORDS)\nstopwords.add(\"bluemix\")\nstopwords.add(\"ibm\")\nstopwords.add(\"NaN\")\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(24, 12))\n\nplt.subplot(2,2,1)\nwordcloud = WordCloud(background_color=\"white\", margin=10, random_state=1, \n                      color_func=random_color_func, stopwords=stopwords, \n                     max_font_size=40, min_font_size=9).generate(tagtext1)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\n\nplt.subplot(2,2,2)\nwordcloud = WordCloud(background_color=\"white\", margin=10, random_state=1, \n                      color_func=random_color_func, stopwords=stopwords, \n                     max_font_size=40, min_font_size=9).generate(tagtext2)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\n\nplt.subplot(2,2,3)\nwordcloud = WordCloud(background_color=\"white\", margin=10, random_state=1, \n                      color_func=random_color_func, stopwords=stopwords, \n                     max_font_size=40, min_font_size=9).generate(tagtext3)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\n\nplt.subplot(2,2,4)\nwordcloud = WordCloud(background_color=\"white\", margin=10, random_state=1, \n                      color_func=random_color_func, stopwords=stopwords, \n                     max_font_size=40, min_font_size=9).generate(tagtext4)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\n\n\nplt.show()", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "print datetime.fromtimestamp(sodf2['creation'].min()).strftime('%Y-%m-%d')\n\n#sodf2['creation'].max() ", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "The difference of users between cloudant, couchdb, dashdb and pouchdb.\n\nThere is a large overlp in keywords, so the question is now if there is a way to seperate out the 4 different products based on the \n\n* reputation of th question owner\n* accept rate of the question owner\n* nuber of views of the question\n* question score\n* key words\n\n\n"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# split users into experts and beginners\nexperts = sodf.where(sodf['reputation']>1000).dropna(subset=['reputation'])\n\nbeginners = sodf.where(sodf['reputation']<1000).dropna(subset=['reputation'])\n\nprint len(experts)", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "### Number of unique users and their experience\n\n### Are there unique groups of users? Any classification of users possible? "}, {"cell_type": "markdown", "metadata": {}, "source": "## Question tags over time"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "# top 5 tags\ntop5tags = sodf2.select(sodf2.tags.alias(\"tag\")).groupBy(\"tag\").count().orderBy([\"count\"], ascending=[0])\ntop5 = top5tags.head(5)\n\n#datetime.fromtimestamp(1486667728)", "metadata": {"collapsed": false, "pixiedust": {"displayParams": {"handlerId": "histogram", "rowCount": "100", "rug": "false", "rendererId": "matplotlib", "aggregation": "SUM", "binsize": "11", "valueFields": "owner_reputation", "kde": "false"}}}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "#tag1 = sodf2.select(sodf2.creation.alias(\"created\"),sodf2.tags.alias(\"tag\"))\n\ncheck=top5[0].tag\n\ngrouped = sodf2.groupBy('creation','tags').count()\n\n#tag1 = sodf2.filter(color_df[9]='apache-spark]')\n\n#\\\n#    .where(sodf2.tags = top5[0].tag)\n\n#df.filter($\"foo\".contains(\"bar\"))\n\ngrouped.show(20)", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "tagsS = sodf['tags'].apply(pd.Series)\ntagsS = tagsS.rename(columns = lambda x: 'tags_' + str(x))\n\nsodf2 = pd.concat([sodf[:], tagsS[:]], axis=1)\n\nsodf2['cloudant']=sodf2['tags'].apply(lambda x: 'cloudant' in x)\nsodf2['dashdb']=sodf2['tags'].apply(lambda x: 'dashdb' in x)\nsodf2['pixiedust']=sodf2['tags'].apply(lambda x: 'pixiedust' in x)\n\nsodf2.head()", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "rows = []\n_ = sodf.apply(lambda x: [rows.append([x['id'], x['answer_count'], x['closed'], x['creation'], x['answered'], x['owner_accept_rate'], x['owner_reputation'], x['score'], x['views'],nn])\n                                  for nn in x.tags], axis =1)\n\nsodf3 = pd.DataFrame(rows,columns=sodf.columns)\nsodf3.head()", "metadata": {"collapsed": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "tag_counts = pd.DataFrame(sodf3.groupby('tags').size().rename('counts'))\ntag_count = tag_counts.sort_values(['counts'], ascending=[False])\nprint len(tag_count), 'unique tags'\ntag_count.head(10)", "metadata": {"collapsed": false}}, {"cell_type": "markdown", "metadata": {}, "source": "## Data visualisations"}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "display(sodf3.sort_values(['counts'], ascending=[False]))", "metadata": {"collapsed": false, "pixiedust": {"displayParams": {"handlerId": "barChart", "orientation": "horizontal", "rowCount": "100", "keyFields": "tags", "valueFields": "id", "aggregation": "COUNT"}}}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": "", "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.0", "language": "python", "name": "python2-spark20"}, "language_info": {"codemirror_mode": {"version": 2, "name": "ipython"}, "version": "2.7.11", "name": "python", "pygments_lexer": "ipython2", "nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py"}}, "nbformat": 4}